{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Used the combined EPIE corpus to build a custom RNN classifier to recognize sentences with idioms and without with ~67% accuracy.\n",
    "- Models consist of 1 embedding layer with 2 dense layers with 50% dropout\n",
    "- Compared the accuracy of models with 1 and 2 Bidirectional LSTM Layers in between the embedding and dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\siddh\\anaconda3\\envs\\project\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\siddh\\anaconda3\\envs\\project\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from official.nlp import optimization  # to create AdamW optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_text as text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the text data from the file\n",
    "with open('combined.txt', 'r', encoding='utf-8') as file:\n",
    "    text_data = file.readlines()\n",
    "\n",
    "# Create labels (half 0s and half 1s)\n",
    "labels = [1] * (len(text_data) // 2) + [0] * (len(text_data) // 2)\n",
    "\n",
    "# Combine text and labels\n",
    "data = list(zip(text_data, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A person who prioritizes actions and deeds over discussion or contemplation all his life , David went into the Army in the RAMC as a young man and later trained as a State Registered Nurse in a civilian hospital .\n",
      "Label: 0 (Not)\n",
      "Sentence: Route-finding is easy to begin with , though enthusiastic signposting unfortunately ceases to function just when paths become undefined , across fields .\n",
      "Label: 0 (Not)\n",
      "Sentence: But he 's my husband , and even if we do stray now and again , we will always be an item . ’\n",
      "Label: 1 (Idiom)\n"
     ]
    }
   ],
   "source": [
    "# Load the text data from the file\n",
    "with open('combined.txt', 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "text_data = text_data.replace(\"\\xe2\\x80\\x98\", \"‘\")\n",
    "text_data = text_data.replace(\"\\xe2\\x80\\x99\", \"’\")\n",
    "    \n",
    "text_data = text_data.split('\\n')\n",
    "\n",
    "# Create labels (half 0s and half 1s)\n",
    "labels = [1] * (len(text_data) // 2) + [0] * (len(text_data) // 2)\n",
    "\n",
    "# Combine text and labels\n",
    "data = list(zip(text_data, labels))\n",
    "\n",
    "# Shuffle the combined data\n",
    "random.seed(42)  # For reproducibility\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split the combined data into training, validation, and test sets\n",
    "num_samples = len(data)\n",
    "num_train = int(0.6 * num_samples)\n",
    "num_val = int(0.2 * num_samples)\n",
    "\n",
    "train_data = data[:num_train]\n",
    "val_data = data[num_train:num_train+num_val]\n",
    "test_data = data[num_train+num_val:]\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "batch_size = 32\n",
    "\n",
    "def text_label_generator(data):\n",
    "    for text, label in data:\n",
    "        yield text, label\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: text_label_generator(train_data),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "train_ds = train_ds.shuffle(buffer_size=num_train)\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: text_label_generator(val_data),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: text_label_generator(test_data),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "class_names = ['Not', 'Idiom']  # Labels for 0 and 1\n",
    "\n",
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    for i in range(3):\n",
    "        sentence = text_batch[i].numpy().decode('utf-8')  # Decoding the bytes to string\n",
    "        label = label_batch[i].numpy()\n",
    "        print(f'Sentence: {sentence}')\n",
    "        print(f'Label: {label} ({class_names[label]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [b'Your quick response in an emergency could be a life-saver for your child .'\n",
      " b\"Wolves may not howl here in the moonlight , as they did in the journal of Jonathan Harker , but I have no difficulty in seeing Slains as he saw Count Dracula 's castle in Bukovina , the tall black windows from which not a glimmer of light came , and the jagged battlements glimpsed when the moon CAME OUT FROM BEHIND the fitful clouds .\"\n",
      " b'The Minister had planned a speech of thanks himself during a visit to Stoke Mandeville Hospital \\xe2\\x80\\xa6 but Adis Avdic lessened his praise, force or authority .']\n",
      "\n",
      "labels:  [1 0 0]\n",
      "texts:  [b\"And then we 're going to use a very nice cream erm called moisture balance and that 's a dermatological product and , and that 's for keeping the skin nice and soft , and keeping the wrinkles at a safe distance .\"\n",
      " b'If it is too drastic to begin without guidance, assistance or preparation with such a sweeping change , why not try it out in experimental matches , festival or night matches ?'\n",
      " b'As presentation day grew closer with Mark racing against time to complete the plan and finalise the slide illustrations , so Klepner read and re-read it until he had almost learnt it off by heart .']\n",
      "\n",
      "labels:  [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_ds.take(2):\n",
    "  print('texts: ', example.numpy()[:3])\n",
    "  print()\n",
    "  print('labels: ', label.numpy()[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_ds.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'the', 'to', 'and', 'a', 'of', 'in', 'that', 'it',\n",
       "       'i', 'was', 'he', 'for', '’', 'with', 'not', '‘', 'is', 's'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4,  71,  32, 119, 105,   3, 253,   5,  77, 772,   1, 226, 228,\n",
       "          1, 600,   4,   8,  19,   5,   1,   1,   4,   4,   8,  19,  13,\n",
       "        121,   2,   1, 772,   4,   1,   4, 121,   2,   1,  24,   5, 112,\n",
       "        122,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0],\n",
       "       [ 52,   9,  18, 118,   1,   3, 680, 156,   1,   1,  44,   1,  15,\n",
       "        131,   5,   1, 501, 272,  16, 323,   9,  42,   7,   1,   1,   1,\n",
       "         44, 174,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0],\n",
       "       [ 23,   1, 235,   1,   1,  15,   1,   1, 180,  62,   3, 880,   2,\n",
       "          1,   4,   1,   2,   1,   1,  49,   1, 569,   4,   1,   9, 208,\n",
       "         12,  29, 410,   1,   9,  98,  33, 204,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_example = encoder(example)[:3].numpy()\n",
    "encoded_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  b\"And then we 're going to use a very nice cream erm called moisture balance and that 's a dermatological product and , and that 's for keeping the skin nice and soft , and keeping the wrinkles at a safe distance .\"\n",
      "Round-trip:  and then we re going to use a very nice [UNK] erm called [UNK] balance and that s a [UNK] [UNK] and and that s for keeping the [UNK] nice and [UNK] and keeping the [UNK] at a safe distance                  \n",
      "\n",
      "Original:  b'If it is too drastic to begin without guidance, assistance or preparation with such a sweeping change , why not try it out in experimental matches , festival or night matches ?'\n",
      "Round-trip:  if it is too [UNK] to begin without [UNK] [UNK] or [UNK] with such a [UNK] change why not try it out in [UNK] [UNK] [UNK] or night [UNK]                             \n",
      "\n",
      "Original:  b'As presentation day grew closer with Mark racing against time to complete the plan and finalise the slide illustrations , so Klepner read and re-read it until he had almost learnt it off by heart .'\n",
      "Round-trip:  as [UNK] day [UNK] [UNK] with [UNK] [UNK] against time to complete the [UNK] and [UNK] the [UNK] [UNK] so [UNK] read and [UNK] it until he had almost [UNK] it off by heart                        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n in range(3):\n",
    "  print(\"Original: \", example[n].numpy())\n",
    "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "print([layer.supports_masking for layer in model.layers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "[0.00442513]\n"
     ]
    }
   ],
   "source": [
    "# predict on a sample text without padding.\n",
    "\n",
    "sample_text = ('The movie was cool. The animation and the graphics '\n",
    "               'were out of this world. I would recommend this movie.')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 263ms/step\n",
      "[0.00442513]\n"
     ]
    }
   ],
   "source": [
    "# predict on a sample text with padding\n",
    "\n",
    "padding = \"the \" * 2000\n",
    "predictions = model.predict(np.array([sample_text, padding]))\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 20s 115ms/step - loss: 0.6930 - accuracy: 0.4959 - val_loss: 0.6927 - val_accuracy: 0.5250\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 17s 137ms/step - loss: 0.6918 - accuracy: 0.4959 - val_loss: 0.6917 - val_accuracy: 0.5250\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 16s 132ms/step - loss: 0.6876 - accuracy: 0.4959 - val_loss: 0.6857 - val_accuracy: 0.5250\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 16s 132ms/step - loss: 0.6668 - accuracy: 0.5073 - val_loss: 0.6628 - val_accuracy: 0.5562\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 17s 138ms/step - loss: 0.6206 - accuracy: 0.6221 - val_loss: 0.6360 - val_accuracy: 0.6208\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 16s 128ms/step - loss: 0.5702 - accuracy: 0.6923 - val_loss: 0.6208 - val_accuracy: 0.6229\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 15s 124ms/step - loss: 0.5295 - accuracy: 0.7327 - val_loss: 0.6014 - val_accuracy: 0.6729\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 16s 128ms/step - loss: 0.4967 - accuracy: 0.7505 - val_loss: 0.5956 - val_accuracy: 0.6792\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 16s 128ms/step - loss: 0.4856 - accuracy: 0.7648 - val_loss: 0.5946 - val_accuracy: 0.6812\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 16s 130ms/step - loss: 0.4622 - accuracy: 0.7808 - val_loss: 0.5907 - val_accuracy: 0.6865\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=10,\n",
    "                    validation_data=val_ds,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 26ms/step - loss: 0.6361 - accuracy: 0.6733\n",
      "Test Loss: 0.6361322999000549\n",
      "Test Accuracy: 0.6733067631721497\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.35265735]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = ('its raining cats and dogs')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation = \"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 59s 386ms/step - loss: 0.6918 - accuracy: 0.5371 - val_loss: 0.6915 - val_accuracy: 0.5771\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 33s 276ms/step - loss: 0.6880 - accuracy: 0.5961 - val_loss: 0.6857 - val_accuracy: 0.6031\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 35s 287ms/step - loss: 0.6604 - accuracy: 0.6660 - val_loss: 0.6583 - val_accuracy: 0.6406\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 40s 331ms/step - loss: 0.5981 - accuracy: 0.7159 - val_loss: 0.6409 - val_accuracy: 0.6594\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 37s 307ms/step - loss: 0.5548 - accuracy: 0.7467 - val_loss: 0.6273 - val_accuracy: 0.6698\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 38s 317ms/step - loss: 0.5245 - accuracy: 0.7638 - val_loss: 0.6091 - val_accuracy: 0.6719\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 34s 283ms/step - loss: 0.4961 - accuracy: 0.7824 - val_loss: 0.6159 - val_accuracy: 0.6823\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 38s 319ms/step - loss: 0.4783 - accuracy: 0.7909 - val_loss: 0.6188 - val_accuracy: 0.6760\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 40s 330ms/step - loss: 0.4590 - accuracy: 0.8039 - val_loss: 0.6257 - val_accuracy: 0.6844\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 30s 247ms/step - loss: 0.4477 - accuracy: 0.8060 - val_loss: 0.6286 - val_accuracy: 0.6833\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, epochs=10,\n",
    "                    validation_data=val_ds,\n",
    "                    validation_steps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 43ms/step - loss: 0.6799 - accuracy: 0.6614\n",
      "Test Loss: 0.6798563003540039\n",
      "Test Accuracy: 0.6613546013832092\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
