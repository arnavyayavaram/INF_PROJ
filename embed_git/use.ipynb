{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Used the Universal Sentence Encoder to experiment and compare results using a different encoder for the sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dgdpIvX_rVjU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Tt4o1eKrYEh"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Trying to load a model of incompatible/unknown type. 'C:\\Users\\siddh\\AppData\\Local\\Temp\\tfhub_modules\\063d866c06683311b44b4992fd46003be952409c' contains neither 'saved_model.pb' nor 'saved_model.pbtxt'.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Load the USE model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m module_url \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://tfhub.dev/google/universal-sentence-encoder/4\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m use_model \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39;49mload(module_url)\n",
            "File \u001b[1;32mc:\\Users\\siddh\\anaconda3\\envs\\project\\lib\\site-packages\\tensorflow_hub\\module_v2.py:107\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    102\u001b[0m saved_model_pbtxt_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m    103\u001b[0m     tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mas_bytes(module_path),\n\u001b[0;32m    104\u001b[0m     tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mas_bytes(tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT))\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(saved_model_path) \u001b[39mand\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(saved_model_pbtxt_path)):\n\u001b[1;32m--> 107\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTrying to load a model of incompatible/unknown type. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m contains neither \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m nor \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m    109\u001b[0m                    (module_path, tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PB,\n\u001b[0;32m    110\u001b[0m                     tf\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT))\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m options:\n\u001b[0;32m    113\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mgetattr\u001b[39m(tf, \u001b[39m\"\u001b[39m\u001b[39msaved_model\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m), \u001b[39m\"\u001b[39m\u001b[39mLoadOptions\u001b[39m\u001b[39m\"\u001b[39m):\n",
            "\u001b[1;31mValueError\u001b[0m: Trying to load a model of incompatible/unknown type. 'C:\\Users\\siddh\\AppData\\Local\\Temp\\tfhub_modules\\063d866c06683311b44b4992fd46003be952409c' contains neither 'saved_model.pb' nor 'saved_model.pbtxt'."
          ]
        }
      ],
      "source": [
        "# Load the USE model\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "use_model = hub.load(module_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "l-Z8dQ3luW09"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "P4B2N_xDuf0y"
      },
      "outputs": [],
      "source": [
        "def save_arr(sentence_embeddings,name):\n",
        "    with open(name, 'wb') as f:\n",
        "        pickle.dump(sentence_embeddings, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "aU2ik0xhvPbU"
      },
      "outputs": [],
      "source": [
        "def read_text(file_path):\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for i in range(len(lines)):\n",
        "        lines[i]=lines[i].strip()\n",
        "\n",
        "    return lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "96EvzQY0we2h"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "Pql_0v2QwmLx"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "IyLFuv8dwfTu"
      },
      "outputs": [],
      "source": [
        "def knn(e,sentence_embeddings,k=10):\n",
        "    nbrs = NearestNeighbors(n_neighbors=k)\n",
        "    nbrs.fit(sentence_embeddings)\n",
        "    distances, indices = nbrs.kneighbors([e])\n",
        "    indices=np.squeeze(indices)\n",
        "    return indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "-7Ryaf-DwoJC"
      },
      "outputs": [],
      "source": [
        "def s_score(i,i1,i2):\n",
        "    common = np.intersect1d(np.intersect1d(i, i1), i2)\n",
        "    s = len(common)\n",
        "\n",
        "    print(\"Common elements:\", common)\n",
        "    print(\"Number of common elements:\", s)\n",
        "    return common"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "7y5pd05Cwrgq"
      },
      "outputs": [],
      "source": [
        "def indices(s,sentence_embeddings):\n",
        "    print(s)\n",
        "    e = np.squeeze(use_model([s]))\n",
        "    i = knn(e,sentence_embeddings)\n",
        "    # print(i)\n",
        "    return i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "QCHlWsk7xA74"
      },
      "outputs": [],
      "source": [
        "sentences =read_text(\"1_combined.txt\")\n",
        "sentence_embeddings = use_model(sentences)\n",
        "\n",
        "# sentence_embeddings = torch.tensor(sentence_embeddings.numpy())\n",
        "# save_arr(sentence_embeddings,'bbc_e.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs_VnKom13qQ",
        "outputId": "4ddead47-016f-4e0b-a742-2bc81b3dca7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(54928, 512)\n"
          ]
        }
      ],
      "source": [
        "print(sentence_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ECCfH2XxlgK",
        "outputId": "b380d22c-9ed9-400b-e21a-2e2acba96100"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([1, 512])"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "use_model([\"hi im a small child\"]).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2uYVs37wzBI",
        "outputId": "5fae9742-f657-4260-972f-ca7a255e6f92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i couldnt go outside because its raining cats and dogs\n",
            "i couldnt go outside because its showering cats and dogs\n",
            "i couldnt go outside because its raining cats and wolves\n",
            "Common elements: [  665   666   881 54895]\n",
            "Number of common elements: 4\n",
            "We 'd fight like cat and dog .\n",
            "\n",
            "We 're fair to each other , and we fight like cats and dogs .\n",
            "\n",
            "Have not we put the cat among the pigeons ?\n",
            "\n",
            "Anyone living in a house without a cat is likely to be visited by a stray sooner or later .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "s=\"i couldnt go outside because its raining cats and dogs\"\n",
        "i = indices(s,sentence_embeddings)\n",
        "i1= indices(\"i couldnt go outside because its showering cats and dogs\",sentence_embeddings)\n",
        "i2= indices(\"i couldnt go outside because its raining cats and wolves\",sentence_embeddings)\n",
        "\n",
        "# for x in i:\n",
        "#     print(sentences[x])\n",
        "#     print()\n",
        "\n",
        "# for x in i1:\n",
        "#     print(sentences[x])\n",
        "#     print()\n",
        "\n",
        "# for x in i2:\n",
        "#     print(sentences[x])\n",
        "#     print()\n",
        "\n",
        "y= s_score(i,i1,i2)\n",
        "\n",
        "for x in y:\n",
        "    print(sentences[x])\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
